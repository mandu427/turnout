[["index.html", "Self-reported voter turnout Chapter 1 Introduction", " Self-reported voter turnout Jiyeon Chang 2020-12-18 Chapter 1 Introduction List three questions that you hope you will be able to answer from your research. (It’s ok if these change as your work progresses.) I am interested in exploring the phenomenon of over-reporting of turnout in elections in surveys. The main dataset I use to investigate this is the Cooperative Congressional Election Study (https://cces.gov.harvard.edu/), which asks respondents whether they voted in the recent election. The data includes a variable which indicates whether there is a matching voting record for the respondent. One way to investigate factors that may explain over-reporting is to look at observations for whom there is no record of voting, and see who responded by saying that they did not vote (record matches response) and compare them to those who claim to have voted, even though there is no corresponding record of them having done so. For those who claim to have voted, there are two possible explanations for the missing record. First, it may have been an administrative error. Alternatively, the respondent may not be telling the truth. In this final project, I will see if the share of those who claim to have voted vs. not differ by a number of parameters described below. state (proxies political climate) age; income; race; political affiliation; strength of partisanship (demographic variables) how long Rs have lived at the current address; frequency church attendance (ties to community) by election cycle; general election including presidential vs. off yr etc. (election specific variables) turnout; margin of elections (This data will come from the MIT Elections Data) (if time allows) "],["data-sources.html", "Chapter 2 Data sources", " Chapter 2 Data sources The main dataset I use is the Cooperative Congressional Election Study (https://cces.gov.harvard.edu/). CCES is a 50,000+ person national stratified sample survey administered by YouGov on a biannual basis. For the purpose of this project, I look at the 3 most recent presidential elections for which data is available–that is, 2008, 2012 and 2016. The data from 2016, for instance, includes 64,600 observations and 563 variables. However, I look a subset of this sample, namely those for whom there is no voting record. For the 3 years, this reduces the sample to a total of 13,216 observations. A wide range of variables are included in the dataset, including the main demographic variables (age, gender, state/county of residence, race, education, income, etc.) and an extensive list of questions about political affiliation and attitudes, support for specific candidates and opinions about proposed policies, such as climate change, and gun control. As briefly mentioned above, one of the challenges of using this data is that, for those who claim to have voted (but for whom there is no matching voting record), we won’t ever know whether these people are lying or if there’s been an administrative error. Literature pertaining to the field identifies a number of factors that may predict higher prob. of admin error, e.g. recent change in residence. There are many variables for which the rate of administrate error should not differ across the response categories, e.g. gender, or religion. This is more a problem with the conceptualization of the question rather than a problem with the quality of data, however, and I will address the limitations in the conclusions one can draw from the visualization that I will produce. "],["data-transformation.html", "Chapter 3 Data transformation", " Chapter 3 Data transformation "],["missing-values.html", "Chapter 4 Missing values", " Chapter 4 Missing values "],["results.html", "Chapter 5 Results", " Chapter 5 Results "],["interactive-component.html", "Chapter 6 Interactive component", " Chapter 6 Interactive component "],["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion "]]
